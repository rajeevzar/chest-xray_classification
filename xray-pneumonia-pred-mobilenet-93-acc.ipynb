{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import necessary modules\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom keras import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNet\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nos.listdir('/kaggle/input/')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-07T11:49:07.437636Z","iopub.execute_input":"2024-09-07T11:49:07.437968Z","iopub.status.idle":"2024-09-07T11:49:21.109276Z","shell.execute_reply.started":"2024-09-07T11:49:07.437932Z","shell.execute_reply":"2024-09-07T11:49:21.108363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Image data generators for training, validation, and testing a deep learning model on chest X-ray images, resizing them to 224x224 pixels. The training data is augmented using random transformations like rotation, shifting, zooming, and flipping to enhance model generalization and prevent overfitting. A portion of the training data (20%) is reserved for validation using the validation_split argument. The test data is loaded separately without augmentation, with only pixel values rescaled for normalization. This setup facilitates training, validation, and testing of a binary classification model.","metadata":{}},{"cell_type":"code","source":"#Image dimensions\nIMG_HEIGHT , IMG_WIDTH = 224, 224\n\n#Create ImageDataGenerators for training, validation and test sets.\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.25,\n    height_shift_range=0.25,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='nearest',\n    validation_split = 0.2 # Use 20% of the training data for validation\n)\n\nval_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/chest-xray-pneumonia/chest_xray/train',\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=32,\n    class_mode='binary',  # Use 'categorical' if you have more than two classes\n    subset = 'training'\n)\n\nval_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/chest-xray-pneumonia/chest_xray/train',\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=32,\n    class_mode='binary',\n    subset = 'validation',\n    shuffle = True\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    '/kaggle/input/chest-xray-pneumonia/chest_xray/test',\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=32,\n    class_mode='binary',\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T11:49:23.784446Z","iopub.execute_input":"2024-09-07T11:49:23.785165Z","iopub.status.idle":"2024-09-07T11:49:24.023693Z","shell.execute_reply.started":"2024-09-07T11:49:23.785118Z","shell.execute_reply":"2024-09-07T11:49:24.022833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Here we build a binary classification model using the pre-trained **MobileNet** as the base, excluding its top classification layer. The last five layers of MobileNet are set to be trainable, while the rest are frozen to retain learned features. The model is sequentially constructed by adding dense layers with *ReLU* activation and dropout layers for regularization. The output layer uses a sigmoid activation for binary classification. After compilation with the **Adamax** optimizer and binary cross-entropy loss, the model is run with dummy input data to ensure proper shape inference.","metadata":{}},{"cell_type":"code","source":"# Load the Xception base model without the top (classification) layer\nbase_model = MobileNet(weights='imagenet', include_top=False, pooling='avg', input_shape=(IMG_HEIGHT , IMG_WIDTH, 3))\n\n# Freeze the layers in the base model\nfor layer in base_model.layers[-10:]:\n    layer.trainable = True\n\n# Build Model \nmodel = Sequential()\n\n# Base Model \nmodel.add(base_model)\n\n# Dense Layer 1\nmodel.add(Dense(256, activation='relu'))\n\nmodel.add(Dropout(0.45))\n# Dense Layer 2 \nmodel.add(Dense(128,activation='relu'))\n\nmodel.add(Dropout(0.3))\n\n# Dense Layer 4 \nmodel.add(Dense(64,activation='relu'))\n\n# Output Layer\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile\nmodel.compile(optimizer=Adamax(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Run the model once with dummy data to ensure shape inference\ndummy_input = np.random.random((1, IMG_HEIGHT, IMG_WIDTH, 3))\nmodel(dummy_input)\n\n# Check model summary again\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-09-07T11:50:07.354487Z","iopub.execute_input":"2024-09-07T11:50:07.355302Z","iopub.status.idle":"2024-09-07T11:50:10.178029Z","shell.execute_reply.started":"2024-09-07T11:50:07.355257Z","shell.execute_reply":"2024-09-07T11:50:10.177088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"> We train the model for up to 20 epochs with early stopping and model checkpointing, monitoring validation loss to stop training if it doesn't improve for 5 epochs and saving only the best model.","metadata":{}},{"cell_type":"code","source":"# Define callbacks\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nmodel_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss')\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=20,\n    callbacks=[early_stopping, model_checkpoint],\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T16:47:39.520826Z","iopub.execute_input":"2024-09-06T16:47:39.521300Z","iopub.status.idle":"2024-09-06T17:56:47.523977Z","shell.execute_reply.started":"2024-09-06T16:47:39.521198Z","shell.execute_reply":"2024-09-06T17:56:47.522535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the best model\nmodel.load_weights('best_model.keras')\n\n# Evaluate the model on the test set\ntest_loss, test_acc = model.evaluate(test_generator)\nprint(f\"Test accuracy: {test_acc:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T17:56:47.527837Z","iopub.execute_input":"2024-09-06T17:56:47.528322Z","iopub.status.idle":"2024-09-06T17:57:11.107827Z","shell.execute_reply.started":"2024-09-06T17:56:47.528274Z","shell.execute_reply":"2024-09-06T17:57:11.106490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Predictions on test data, rounds them for binary classification, prints the classification report and confusion matrix, and calculates the ROC curve and AUC score for performance evaluation.","metadata":{}},{"cell_type":"code","source":"# Predict on test data\npredictions = model.predict(test_generator)\npredictions = np.round(predictions).astype(int)\n\n# Classification report\nprint(classification_report(test_generator.classes, predictions))\n\n# Confusion matrix\nprint(confusion_matrix(test_generator.classes, predictions))\n\n# ROC Curve\nfpr, tpr, thresholds = roc_curve(test_generator.classes, predictions)\nroc_auc = auc(fpr, tpr)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T17:57:11.109588Z","iopub.execute_input":"2024-09-06T17:57:11.109992Z","iopub.status.idle":"2024-09-06T17:57:28.790400Z","shell.execute_reply.started":"2024-09-06T17:57:11.109950Z","shell.execute_reply":"2024-09-06T17:57:28.788948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('medical_image_classifier.h5')","metadata":{"execution":{"iopub.status.busy":"2024-09-06T17:57:28.792058Z","iopub.execute_input":"2024-09-06T17:57:28.792458Z","iopub.status.idle":"2024-09-06T17:57:29.127241Z","shell.execute_reply.started":"2024-09-06T17:57:28.792417Z","shell.execute_reply":"2024-09-06T17:57:29.125693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the true labels from the test generator\ntrue_labels = test_generator.classes\n\n# Get the predicted probabilities from the model\npredictions = model.predict(test_generator)\n\n# Convert predicted probabilities to class labels (0 or 1 for binary classification)\npredicted_labels = np.round(predictions).astype(int).reshape(-1)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T17:57:29.133600Z","iopub.execute_input":"2024-09-06T17:57:29.135315Z","iopub.status.idle":"2024-09-06T17:57:45.157477Z","shell.execute_reply.started":"2024-09-06T17:57:29.135251Z","shell.execute_reply":"2024-09-06T17:57:45.156174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(true_labels, predicted_labels)\n\n# Plotting the confusion matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices.keys())\n\n# Plot the matrix\ndisp.plot(cmap=plt.cm.Blues)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T17:57:45.159316Z","iopub.execute_input":"2024-09-06T17:57:45.159857Z","iopub.status.idle":"2024-09-06T17:57:45.407509Z","shell.execute_reply.started":"2024-09-06T17:57:45.159786Z","shell.execute_reply":"2024-09-06T17:57:45.406185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training & validation accuracy values\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T17:57:45.409623Z","iopub.execute_input":"2024-09-06T17:57:45.410129Z","iopub.status.idle":"2024-09-06T17:57:46.028459Z","shell.execute_reply.started":"2024-09-06T17:57:45.410036Z","shell.execute_reply":"2024-09-06T17:57:46.027113Z"},"trusted":true},"execution_count":null,"outputs":[]}]}